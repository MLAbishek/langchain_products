{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef11212a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENROUTER_API_KEY found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.getenv(\"OPENROUTER_API_KEY\") is None:\n",
    "    raise ValueError(\"OPENROUTER_API_KEY not found\")\n",
    "else:\n",
    "    print(\"OPENROUTER_API_KEY found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf358808",
   "metadata": {},
   "source": [
    "# **Chain Invocation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aa4835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llm_schema(topic='AI Fun Fact', fact=\"**AI can 'dream' too!** ðŸŒ™ðŸ¤–\\n\\nResearchers have found that some advanced AI models, like Google's *Dreamer* or OpenAI's *DALLÂ·E*, can generate and even simulate complex, multi-step 'dreams' or hypothetical scenarios in their neural networks. These aren't literal dreams (the AI doesn't have consciousness), but they're internal sequences of imagined states that help the system plan actions for tasks like robotics or video game playingâ€”kind of like a machine rehearsing possible futures to make better decisions. Fun bonus: When you ask an AI like Stable Diffusion to 'imagine' a surreal landscape, itâ€™s technically creating a dream-like abstraction by combining patterns from its training data. ðŸŽ¨âœ¨\\n\\nWould you rather your AI have *cohesive dreams* or *nightmare-level hallucinations*?\")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"mistralai/mistral-7b-instruct\",\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "\n",
    "# Task 1\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"user\", \"Write a fun fact about {topic}.\")\n",
    "])\n",
    "\n",
    "# class llm_schema(BaseModel):\n",
    "#     topic: str\n",
    "#     fact: str\n",
    "\n",
    "# Task 2\n",
    "# new_llm = llm.with_structured_output(llm_schema)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fac6f2a",
   "metadata": {},
   "source": [
    "# **String Output Parser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546faf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Task 3\n",
    "stringparser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f28c3f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = prompt | llm | stringparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cda25ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Artificial Intelligence (AI) is a broad and rapidly evolving field of computer science focused on creating systems or machines that can perform tasks typically requiring **human intelligence**. These tasks include:\\n\\n1. **Learning** â€“ AI can acquire knowledge from data (e.g., machine learning models that improve with experience).\\n2. **Reasoning** â€“ It can analyze information and make logical decisions (e.g., expert systems or rule-based AI).\\n3. **Problem-solving** â€“ AI can find solutions to complex issues by simulating human thought processes (e.g., chess-playing algorithms).\\n4. **Perception** â€“ It understands and processes sensory input like images, speech, and text (e.g., computer vision, natural language processing).\\n5. **Language understanding & generation** â€“ AI can comprehend, translate, and generate human-like text (e.g., large language models like me).\\n6. **Autonomy** â€“ Some AI systems can act independently in controlled environments (e.g., self-driving cars, drones).\\n\\n### **Key AI Subfields:**\\n- **Machine Learning (ML):** AI learns patterns from data without explicit programming (e.g., recommender systems, facial recognition).\\n- **Deep Learning:** A subset of ML using neural networks with many layers to model complex data (e.g., voice assistants, image generation).\\n- **Natural Language Processing (NLP):** Enables computers to understand and produce human language (e.g., chatbots, translation tools).\\n- **Computer Vision:** AI interprets visual data (e.g., self-driving cars, medical imaging).\\n- **Robotics & Automation:** AI powers physical machines (e.g., robotic arms in factories, autonomous vacuum cleaners).\\n- **Expert Systems:** AI mimics human expertise in specific domains (e.g., medical diagnosis, financial analysis).\\n- **Reinforcement Learning:** AI learns through trial and error by receiving rewards or penalties (e.g., game-playing AI like AlphaGo).\\n\\n### **How AI Works:**\\nAI systems rely on:\\n- **Algorithms:** Mathematical rules that process data (e.g., decision trees, neural networks).\\n- **Data:** Large datasets used for training (e.g., text, images, sensor readings).\\n- **Computing Power:** High-performance GPUs/TPUs for complex tasks.\\n- **Hardware:** Computers, sensors, and specialized chips (like AI accelerators).\\n\\n### **Examples of AI in Use Today:**\\n- **Recommendation Systems** (Netflix, Amazon, YouTube).\\n- **Voice Assistants** (Siri, Alexa, Google Assistant).\\n- **Self-Driving Cars** (Tesla, Waymo).\\n- **Healthcare Diagnostics** (AI detecting tumors in medical scans).\\n- **Language Models** (ChatGPT, Bard).\\n- **Fraud Detection** (credit card transaction analysis).\\n\\n### **Is AI Human Intelligence?**\\nNoâ€”AI is **simulated intelligence** based on statistical patterns, not consciousness or true understanding. It lacks emotions, self-awareness, and the ability to feel or experience the world like humans.\\n\\nWould you like a deeper dive into any specific aspect of AI?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 638, 'prompt_tokens': 10, 'total_tokens': 648, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'cost': 0.0001296, 'is_byok': False, 'cost_details': {'upstream_inference_cost': 0.0001296, 'upstream_inference_prompt_cost': 2e-06, 'upstream_inference_completions_cost': 0.0001276}}, 'model_provider': 'openai', 'model_name': 'mistralai/mistral-7b-instruct', 'system_fingerprint': None, 'id': 'gen-1770175927-65u9wNVBLK7LjukQA3Xy', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c26b5-1459-7ad2-a700-f395bfe17b09-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 10, 'output_tokens': 638, 'total_tokens': 648, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afbaad9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hereâ€™s a fun (and mind-blowing) fact about **Data Science**:\\n\\nðŸ”® **Your phoneâ€™s keyboard knows you better than your friends!**\\n\\nModern smartphones use advanced **predictive text models** and **behavioral analytics** to guess what youâ€™re typing *before* you finish. This isnâ€™t just basic autocompleteâ€”itâ€™s a mix of **natural language processing (NLP)**, **user typing patterns**, and even **sentiment analysis**! Companies like Google and Apple analyze your messaging history, word choices, autocorrect habits, and even the *emojis* you use to predict the next word with uncanny accuracy. In some cases, the algorithm is right more than **50% of the time**â€”making it a hidden, real-world example of how data science turns raw inputs (like keystrokes) into hyper-personalized outputs (like your text suggestions).\\n\\nBonus weirdness:\\n- Your typing speed slows down when youâ€™re **angry** (the algorithm detects this!).\\n- Some predictive models even adjust for **time of day** (e.g., faster suggestions in the morning, more sarcastic guesses at 2 AM).\\n- Studies show that people **trust** their phoneâ€™s predictions more than human autocorrect!\\n\\nWant to geek out over the tech behind it? Ask me about **neural networks for language modeling** or how **feature engineering** makes your keyboard so \"smart\"! ðŸš€'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain.invoke({\"topic\": \"Data Science\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25838d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddba9b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1\n",
    "prompt_1 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"user\", \"Generate content about {topic}\")\n",
    "])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2002a872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"mistralai/mistral-7b-instruct\",\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    temperature=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9e03f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3\n",
    "strpars = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f73d95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4 -> Custom Runnable Function\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def dictionary_maker(data: str) -> dict:\n",
    "    return {\"content\": data}\n",
    "\n",
    "dictionary_maker_runnnable = RunnableLambda(dictionary_maker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee1cf4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5\n",
    "prompt_2 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are Linked In Post Generator Assistant.\"),\n",
    "    (\"user\", \"Generate a LinkedIn post for following content {content}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "866a720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 6 -> LLM\n",
    "\n",
    "# Task 7 -> StrOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2afec7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = prompt_1 | llm | strpars | dictionary_maker_runnnable | prompt_2 | llm | strpars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6cb356a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**ðŸš€ LinkedIn Post: \"Agentic AI â€“ The Next Evolution of Intelligent Systems\"**\\n\\n**How far could AI go if it didnâ€™t just *respond*â€¦ but *acted*?**\\n\\nMost AI today is like a super-smart calculatorâ€”it answers questions, predicts trends, and follows scripts. But **Agentic AI** is changing the game. These systems donâ€™t just react; they **plan, execute, and adapt** autonomouslyâ€”just like a human agent wouldâ€”while staying aligned with our goals and values.\\n\\nImagine an AI that:\\nâœ… **Handles complex tasks** without needing constant prompts\\nâœ… **Learns from experience** and remembers past decisions\\nâœ… **Collaborates with other AI agents** (and humans) to solve problems\\nâœ… **Makes real-time adjustments** when circumstances shift\\n\\nThis is the future of **Reinforcement Learning, Neuro-Symbolic AI, and Multi-Agent Systems**â€”where machines donâ€™t just *assist* but *partner* in decision-making.\\n\\n**ðŸ”¹ The Promise:**\\n- **Autonomous research labs** (DeepMindâ€™s AI agents designing experiments)\\n- **Self-optimizing supply chains** (agents coordinating logistics in real time)\\n- **Personalized AI assistants** (Copilot+, Google Autogen) that *understand* your needs before you even ask\\n- **Ethical AI governance** (Constitutional AI, RLHF) keeping them aligned with human intent\\n\\n**ðŸ”¹ The Challenges:**\\nBut with great power comes great responsibility. How do we ensure:\\nâš ï¸ **Safety?**** (Preventing unintended consequences)\\nâš ï¸ **Alignment?**** (AI acting in our best interests)\\nâš ï¸ **Accountability?**** (Whoâ€™s responsible if an AI agent makes a wrong call?)\\nâš ï¸ **Transparency?**** (Explaining AI decisions in high-stakes fields)\\n\\nThe **EU AI Act, DeepMindâ€™s Sparrow, and OpenAIâ€™s fine-tuning** are just a few steps toward building agentic AI thatâ€™s **reliable, trustworthy, and truly helpful**.\\n\\n**ðŸ’¡ Thoughts?**\\nWould you trust an AI agent to make big decisions in your business? Or is this still a conversation for the future?\\n\\n#AI #ArtificialIntelligence #AgenticAI #FutureOfWork #DeepLearning #ReinforcementLearning #NeuroSymbolicAI #EthicalAI #TechInnovation #Automation #DeepMind #OpenAI #Microsoft #GoogleAI\\n\\n---\\n**Why this works for LinkedIn:**\\nâœ” **Engaging hook** â€“ Challenges the audienceâ€™s perception of AI\\nâœ” **Clear structure** â€“ Explains *what*, *how*, *applications*, and *future* in a skimmable way\\nâœ” **Interactive call-to-action** â€“ Encourages discussion and debate\\nâœ” **Trending hashtags** â€“ Boosts visibility in AI, automation, and enterprise tech circles\\nâœ” **Balanced optimism & caution** â€“ Highlights both potential and ethical concerns\\n\\n**Optional tweaks:**\\n- Add a **short video or animation** explaining agentic AI (e.g., Microsoft Copilot+ demo)\\n- Tag a **thought leader** (e.g., @DemisHassabis, @SatyaNadella, @YannLeCun) to spark conversation\\n- If youâ€™re in a specific industry (finance, healthcare, etc.), **tailor examples** to your network\\n\\nWant a **shorter version** or a **focus on one sector**? Let me know! ðŸš€'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain.invoke({\"topic\": \"Agentic AI\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b97ddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class llm_schema(BaseModel):\n",
    "    topic: str = Field(description=\"The topic for the joke\")\n",
    "    fact: str = Field(description=\"The fact for the joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79afa8b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4b21575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llm_schema(topic='Microsoft', fact='Microsoft Corporation is a prominent American multinational technology company headquartered in Redmond, Washington. It is known for developing, manufacturing, licensing, and supporting software, computers, electronics, and services.\\n\\nHereâ€™s a comprehensive overview as of my last knowledge update in October 2023:\\n\\n\\n### **History**\\n- Founded on **April 4, 1975**, by **Bill Gates** and **Paul Allen** in Albuquerque, New Mexico (later moved to Washington).\\n- Initially developed **MS-DOS**, the dominant operating system for personal computers in the 1980s.\\n- Released **Windows 1.0** in 1985, which became the leading OS for PCs globally over time.\\n- The 1990s saw Microsoft dominating with Windows and Office, leading to antitrust lawsuits in the US and Europe.\\n- Entered the 2000s with heavy investment in cloud computing (e.g., **Azure**) and digital services (e.g., **Xbox**).\\n\\n### **Key Products and Services**\\n1. **Operating Systems:**\\n   - **Windows**: The most widely used OS for personal computers (versions include Windows 10, Windows 11).\\n   - **Windows Server**: Used in enterprise environments (e.g., Windows Server 2022 was released in September 2023).\\n\\n2. **Productivity Software:**\\n   - **Microsoft Office**: Includes Word, Excel, PowerPoint, Outlook, and Teams (subscription-based **Microsoft 365** is now the standard).\\n   - **Teams**: A communication platform used for video meetings, chat, and collaboration (popularized during the pandemic).\\n\\n3. **Cloud Computing:**\\n   - **Microsoft Azure**: A cloud platform for building, testing, and deploying apps (competes with AWS and Google Cloud).\\n   - **Office 365/Azure AD**: Enterprise cloud services for identity, security, and compliance.\\n\\n4. **Gaming:**\\n   - **Xbox**: A line of gaming consoles (e.g., Xbox Series X/S, Xbox Game Pass).\\n\\n5. **Development Tools:**\\n   - **Visual Studio**: An IDE for software development.\\n   - **.NET Framework**: A software framework for building apps.\\n\\n6. **Hardware:**\\n   - **Surface**: A line of laptops, tablets, and hybrid devices.\\n   - **Xbox**: Gaming consoles and accessories.\\n\\n7. **Search and AI:**\\n   - **Bing**: A web search engine (replaced MSN Search).\\n   - **Copilot**: AI assistant integrated with Windows, Bing, and Office.\\n   - **GitHub Copilot**: AI-powered coding tool that assists developers.\\n\\n8. **Entertainment:**\\n   - **Microsoft Studios**: Owns or partners with major film/TV studios (e.g., **MGM**, **20th Century Studios**).\\n   - **Xbox Game Studios**: Acquired Game Studios like **Activision Blizzard**, **Bethesda Softworks**, and **Turn 10 Studios** (e.g., Call of Duty, Elder Scrolls, Forza).\\n\\n### **Leadership**\\n- **Satya Nadella**: CEO since 2014 (focused on cloud computing, AI, and cultural transformation).\\n- **Bill Gates**: Co-founder and former CEO/Chairman (now Technical Advisor and focuses on philanthropy via the **Bill & Melinda Gates Foundation**).\\n\\n### **Acquisitions and Growth**\\n- Major acquisitions include **LinkedIn (2016)**, **GitHub (2018)**, and **Activision Blizzard (2023)**.\\n- Investments in AI (e.g., **Microsoftâ€™s partnership with OpenAI**) and quantum computing.\\n\\n### **Business Segments**\\n1. **Productivity and Business Processes**: Office, Teams, Dynamics 365.\\n2. **Intelligent Cloud**: Azure, LinkedIn, enterprise services.\\n3. **More Personal Computing**: Windows, Surface, Xbox.\\n4. **AI and Data Platform**: Copilot, AI tools, and machine learning services.\\n\\n### **Recent Developments (as of October 2023)**\\n- **Activision Blizzard Deal**: Microsoftâ€™s $69 billion acquisition of Activision Blizzard (pending regulatory approval) marked a major entry into the gaming industry.\\n- **AI Expansion**: Heavy focus on AI, including **Windows Copilot** and **Azure AI services**.\\n- **Surface Devices**: Release of new Surface Pro and Surface Laptop models.\\n- **Windows 11 Updates**: Features like **Copilot integration** and **AI tools**.\\n\\n### **Financial Performance**\\n- Microsoft is one of the largest companies globally by market cap (consistently ranking in the top 3 as of late 2023).\\n- Revenue streams include software licenses, cloud services, gaming, and hardware.\\n\\n### **Reputation and Criticisms**\\n- **Monopoly Allegations**: Past legal battles (e.g., **US v. Microsoft**, 2001) over anti-competitive practices.\\n- **Privacy Concerns**: Windows telemetry and data collection features have faced scrutiny.\\n- **Evolving Image**: Shifted from Windows-centric dominance to cloud, AI, and gaming.\\n\\n### **Philanthropy**\\n- **Bill & Melinda Gates Foundation**: One of the largest private foundations in the world, focusing on global health, education, and poverty alleviation.\\n\\n### **Notable Culture and Diversity Initiatives**\\n- Microsoft has been recognized for progressive workplace policies, including parental leave, LGBTQ+ inclusion, and diversity training.\\n\\n--- \\n**Would you like me to clarify or update any specific aspect of Microsoftâ€™s current status?** Keep in mind that while I can provide context up to October 2023, I may not have the latest details unless you share them!**\\n---')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_llm = llm.with_structured_output(llm_schema)\n",
    "\n",
    "response = new_llm.invoke(\"Tell me about Microsoft\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "175c7013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'Microsoft',\n",
       " 'fact': 'Microsoft Corporation is a prominent American multinational technology company headquartered in Redmond, Washington. It is known for developing, manufacturing, licensing, and supporting software, computers, electronics, and services.\\n\\nHereâ€™s a comprehensive overview as of my last knowledge update in October 2023:\\n\\n\\n### **History**\\n- Founded on **April 4, 1975**, by **Bill Gates** and **Paul Allen** in Albuquerque, New Mexico (later moved to Washington).\\n- Initially developed **MS-DOS**, the dominant operating system for personal computers in the 1980s.\\n- Released **Windows 1.0** in 1985, which became the leading OS for PCs globally over time.\\n- The 1990s saw Microsoft dominating with Windows and Office, leading to antitrust lawsuits in the US and Europe.\\n- Entered the 2000s with heavy investment in cloud computing (e.g., **Azure**) and digital services (e.g., **Xbox**).\\n\\n### **Key Products and Services**\\n1. **Operating Systems:**\\n   - **Windows**: The most widely used OS for personal computers (versions include Windows 10, Windows 11).\\n   - **Windows Server**: Used in enterprise environments (e.g., Windows Server 2022 was released in September 2023).\\n\\n2. **Productivity Software:**\\n   - **Microsoft Office**: Includes Word, Excel, PowerPoint, Outlook, and Teams (subscription-based **Microsoft 365** is now the standard).\\n   - **Teams**: A communication platform used for video meetings, chat, and collaboration (popularized during the pandemic).\\n\\n3. **Cloud Computing:**\\n   - **Microsoft Azure**: A cloud platform for building, testing, and deploying apps (competes with AWS and Google Cloud).\\n   - **Office 365/Azure AD**: Enterprise cloud services for identity, security, and compliance.\\n\\n4. **Gaming:**\\n   - **Xbox**: A line of gaming consoles (e.g., Xbox Series X/S, Xbox Game Pass).\\n\\n5. **Development Tools:**\\n   - **Visual Studio**: An IDE for software development.\\n   - **.NET Framework**: A software framework for building apps.\\n\\n6. **Hardware:**\\n   - **Surface**: A line of laptops, tablets, and hybrid devices.\\n   - **Xbox**: Gaming consoles and accessories.\\n\\n7. **Search and AI:**\\n   - **Bing**: A web search engine (replaced MSN Search).\\n   - **Copilot**: AI assistant integrated with Windows, Bing, and Office.\\n   - **GitHub Copilot**: AI-powered coding tool that assists developers.\\n\\n8. **Entertainment:**\\n   - **Microsoft Studios**: Owns or partners with major film/TV studios (e.g., **MGM**, **20th Century Studios**).\\n   - **Xbox Game Studios**: Acquired Game Studios like **Activision Blizzard**, **Bethesda Softworks**, and **Turn 10 Studios** (e.g., Call of Duty, Elder Scrolls, Forza).\\n\\n### **Leadership**\\n- **Satya Nadella**: CEO since 2014 (focused on cloud computing, AI, and cultural transformation).\\n- **Bill Gates**: Co-founder and former CEO/Chairman (now Technical Advisor and focuses on philanthropy via the **Bill & Melinda Gates Foundation**).\\n\\n### **Acquisitions and Growth**\\n- Major acquisitions include **LinkedIn (2016)**, **GitHub (2018)**, and **Activision Blizzard (2023)**.\\n- Investments in AI (e.g., **Microsoftâ€™s partnership with OpenAI**) and quantum computing.\\n\\n### **Business Segments**\\n1. **Productivity and Business Processes**: Office, Teams, Dynamics 365.\\n2. **Intelligent Cloud**: Azure, LinkedIn, enterprise services.\\n3. **More Personal Computing**: Windows, Surface, Xbox.\\n4. **AI and Data Platform**: Copilot, AI tools, and machine learning services.\\n\\n### **Recent Developments (as of October 2023)**\\n- **Activision Blizzard Deal**: Microsoftâ€™s $69 billion acquisition of Activision Blizzard (pending regulatory approval) marked a major entry into the gaming industry.\\n- **AI Expansion**: Heavy focus on AI, including **Windows Copilot** and **Azure AI services**.\\n- **Surface Devices**: Release of new Surface Pro and Surface Laptop models.\\n- **Windows 11 Updates**: Features like **Copilot integration** and **AI tools**.\\n\\n### **Financial Performance**\\n- Microsoft is one of the largest companies globally by market cap (consistently ranking in the top 3 as of late 2023).\\n- Revenue streams include software licenses, cloud services, gaming, and hardware.\\n\\n### **Reputation and Criticisms**\\n- **Monopoly Allegations**: Past legal battles (e.g., **US v. Microsoft**, 2001) over anti-competitive practices.\\n- **Privacy Concerns**: Windows telemetry and data collection features have faced scrutiny.\\n- **Evolving Image**: Shifted from Windows-centric dominance to cloud, AI, and gaming.\\n\\n### **Philanthropy**\\n- **Bill & Melinda Gates Foundation**: One of the largest private foundations in the world, focusing on global health, education, and poverty alleviation.\\n\\n### **Notable Culture and Diversity Initiatives**\\n- Microsoft has been recognized for progressive workplace policies, including parental leave, LGBTQ+ inclusion, and diversity training.\\n\\n--- \\n**Would you like me to clarify or update any specific aspect of Microsoftâ€™s current status?** Keep in mind that while I can provide context up to October 2023, I may not have the latest details unless you share them!**\\n---'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac28c280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0b5d589",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"mistralai/mistral-7b-instruct\",\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    temperature=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb91997b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a product description feature extraction assistant.\"),\n",
    "    (\"user\", \"Extract features from the following product description: {description}\"),\n",
    "])\n",
    "\n",
    "class llm_schema1(BaseModel):\n",
    "    product: str = Field(description=\"Product name\")\n",
    "    features: List[str] = Field(description=\"List of features\")\n",
    "\n",
    "llm1 = llm.with_structured_output(llm_schema1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71e87e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dict(llm_response) -> dict:\n",
    "    return llm_response.model_dump()\n",
    "\n",
    "convert_to_dict_runnable = RunnableLambda(convert_to_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2346c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a marketing angles generator.\"),\n",
    "    (\"user\", '''Generate marketing angles for the following product details: \n",
    "    Product Name: {product}\n",
    "    Features: {features}'''),\n",
    "])\n",
    "\n",
    "class llm_schema2(BaseModel):\n",
    "    product: str = Field(description=\"Product name\")\n",
    "    angles: List[str] = Field(description=\"List of marketing angles\")\n",
    "\n",
    "llm2 = llm.with_structured_output(llm_schema2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fb9d948",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a marketing email generator.\"),\n",
    "    (\"user\", '''Generate marketing email for the following product details: \n",
    "    Product Name: {product}\n",
    "    Marketing Angles: {angles}'''),\n",
    "])\n",
    "\n",
    "llm3 = llm\n",
    "\n",
    "strparser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac0b6253",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1 = prompt1 | llm1 | convert_to_dict_runnable | prompt2 | llm2 | convert_to_dict_runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acc91ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = prompt1 | llm1 | convert_to_dict_runnable | prompt2 | llm2 | convert_to_dict_runnable | prompt3 | llm3 | strparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd00099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain.invoke({\"description\": '''Elegant Round 1.5â€³ HD Display â€“ Experience premium clarity and style with a circular HD screen that offers rich color depth, smooth touch response, and an always-on display mode for quick time checks.\n",
    "Built-in Front Camera + Nano-SIM Support â€“ Capture selfies and make video calls directly from your wrist with the integrated 2 MP camera. Insert a nano-SIM to use it as a standalone watch phone.\n",
    "Seamless Bluetooth Calling â€“ Stay connected without touching your phone. Make and receive calls directly from your wrist with an in-built mic and speaker for clear, stable sound quality.\n",
    "Multiple Sports & Activity Modes â€“ From running and cycling to yoga and strength training, track your daily workouts with precision and view your progress in the companion app.\n",
    "Smart Notifications & Controls â€“ Get alerts for calls, SMS, WhatsApp, and social apps. Control music, camera, and more right from your wrist for effortless multitasking.'''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b5b4ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'product': 'Smart Watch with HD Display',\n",
       " 'angles': ['**1. Premium Display for Stunning Visuals**',\n",
       "  'Experience crystal-clear visuals with our **1.5-inch circular HD screen**, offering **rich color depth** and **smooth touch response**. Perfect for reading notifications, browsing photos, and enjoying a vibrant display even in bright sunlight. **Always-on display mode** ensures you never miss a beat and can quickly check the time without waking the display.',\n",
       "  '**2. Standalone Watch Phone with Nano-SIM Support**',\n",
       "  'Never miss a call or message thanks to the integrated **2 MP front-facing camera** and **nano-SIM support**. Take crystal-clear selfies, engage in high-quality video calls, and enjoy call clarity with **built-in mic and speaker**â€”all from your **Smart Watch**. Stay connected hands-free with **seamless Bluetooth calling** for true convenience and freedom.',\n",
       "  '**3. Perfect Fit for All Fitness Enthusiasts**',\n",
       "  \"Whether you're a **runner, cyclist, yogi, or weightlifter**, our smart watch has you covered. It features **multiple sports modes** and **precision tracking** for all your daily workouts. View and compare your progress with the **companion app**, and get tailored insights to help you reach your fitness goals.\",\n",
       "  '**4. Never Look Down Again â€“ Your Smart Companion**',\n",
       "  'Get more done with the **always-on HD display** and **on-wrist controls** for your music, camera, and other essential features. Enjoy **smart notifications** for calls, SMS, WhatsApp, social media, and more without needing to pull out your phone. **Effortless multitasking** keeps you in control, right from your wrist.',\n",
       "  '**5. Superior Audio with Built-in Mic and Speaker**',\n",
       "  'Our smart watch is now equipped with a **built-in mic and speaker**, ensuring clear and stable sound quality. Perfect for hands-free video calls, receiving important alerts, and controlling music with ease. **Enjoy crisp audio wherever you go without needing external devices**!',\n",
       "  '**6. Stay Connected Hands-Free with Seamless Bluetooth**',\n",
       "  'Forget about fumbling with your phone every time you get a call or notification. Our smart watch offers **hands-free Bluetooth calling** and **smart notifications** for instant access to all your important messages, calls, and updates. Your essential communication is just a glance away.',\n",
       "  '**7. Uninterrupted Tracking for Your Wellness Journey**',\n",
       "  'Track your **daily workouts** with precision and view detailed progress right on your **Smart Watch**. With the help of the **companion app**, you get a comprehensive snapshot of your fitness activities, helping you stay on top of your health and wellness goals.',\n",
       "  '**8. Ultra-Reliable and Easy to Use**',\n",
       "  'Built for **reliability** and **ease of use**, our smart watch features an **HD display with smooth touch response**, **always-on mode**, and a **user-friendly interface**. The **on-wrist controls** make it simple to manage everything from your fitness tracking to music playback and camera functions.',\n",
       "  '**9. The Ultimate Gadget for Tech-Savvy Fitness Lovers**',\n",
       "  'Our **Smart Watch with HD Display** is designed for those who want to merge the latest technology with their fitness routine. Enjoy **smart notifications**, **premium display quality**, and **standalone phone capabilities**â€”all in one sleek, wearable device.',\n",
       "  '**10. Ideal for Busy Professionals Who Value Time**',\n",
       "  'For busy professionals on the go, our smart watch is the perfect tool to **save time and stay efficient**. Quickly respond to calls and messages, control music with just a tap, and keep an eye on your workout statsâ€”all while looking polished and professional in the boardroom or on the treadmill.',\n",
       "  '**11. Perfect for Casual Users Looking for a Reliable Smart Watch**',\n",
       "  \"Even if you're not a tech enthusiast, our smart watch is built to fit your needs seamlessly. Enjoy **smart notifications** and **on-wrist controls** for essential tasks like music playback and time checks, ensuring you can stay connected and informed without complexity.\",\n",
       "  '**12. A Trusted Fitness Partner with Nano-SIM Convenience**',\n",
       "  'Combine **trusted fitness tracking** with the convenience of **standalone phone features**â€”no need to carry your bulky smartphone. Our smart watch supports **nano-SIM** for calls and messages, providing a **smart, compact, and efficient** way to monitor your health and stay connected.',\n",
       "  '**13. Clearer Visuals, Brighter Future â€“ HD Display Tech**',\n",
       "  'Upgrade your smartwatch game with our **1.5-inch HD screen**. Experience **rich color depth** and **smooth touch response**, making it ideal for outdoor adventures, quick glances at notifications, and crisp video calls. **Your future just got a lot clearer**!',\n",
       "  '**14. Stay Informed with Instant Smart Notifications**',\n",
       "  'Our smart watch sends **instant notifications** right to your wrist for calls, SMS, WhatsApp, and social media. Stay updated on important messages, never miss a call, and manage your communication with effortless **on-wrist controls**. **Information is powerâ€”and itâ€™s now on your wrist**!',\n",
       "  '**15. Multitasking Made Easy with On-Wrist Controls**',\n",
       "  'The days of juggling multiple devices are over. Our smart watch offers **on-wrist controls** for music, camera, and other key features, enabling **effortless multitasking**. Easily switch between activities, capture memories, and listen to your tunes without needing to stop and pull out your phone.',\n",
       "  '**16. Superior Image Quality in a Standalone Device**',\n",
       "  'Capture stunning selfies and join video calls with **crisp clarity**â€”even with the **2 MP front-facing camera** in a standalone smartwatch. The vibrant **1.5-inch HD screen** ensures you see and are seen clearly. **Itâ€™s like having a phone in your watch, but better**!',\n",
       "  '**17. Go Beyond Fitness Tracking with Smart Conveniences**',\n",
       "  'Why settle for just a fitness tracker? Our **Smart Watch** brings you **multiple sports modes**, **precise activity tracking**, and a host of **sleek smart features**. From **smart notifications** to **on-wrist controls**, itâ€™s the perfect blend of workout insights and everyday convenience.',\n",
       "  '**18. Your Pocket-Sized Smartphone Just Got Smarter**',\n",
       "  'With a **2 MP front-facing camera**, **built-in speaker and mic**, and **nano-SIM support**, our **smart watch isnâ€™t just a fitness deviceâ€”itâ€™s your pocket-sized smartphone**. Experience **standalone calling and photography** without missing out on essential features.',\n",
       "  '**19. Effortless Monitoring, Unmatched Performance**',\n",
       "  'Get **unmatched performance** with **seamless connectivity** and **effortless monitoring** of your daily activities. The **companion app** provides detailed insights, while the **HD display** and **on-wrist controls** make navigation a breeze. **Stay in tune with your health and life** on the go.',\n",
       "  '**20. Smart Watch for the Style-Conscious and Tech-Savvy**',\n",
       "  'Stand out with a **trendy smartwatch** that does it all! Our **1.5-inch HD screen** offers a stunning display, and features like **on-wrist controls**, **smart notifications**, and **standalone phone capabilities** make it a must-have for the **tech-aware and fashion-forward**. **']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain1.invoke({\"description\": '''Elegant Round 1.5â€³ HD Display â€“ Experience premium clarity and style with a circular HD screen that offers rich color depth, smooth touch response, and an always-on display mode for quick time checks.\n",
    "Built-in Front Camera + Nano-SIM Support â€“ Capture selfies and make video calls directly from your wrist with the integrated 2 MP camera. Insert a nano-SIM to use it as a standalone watch phone.\n",
    "Seamless Bluetooth Calling â€“ Stay connected without touching your phone. Make and receive calls directly from your wrist with an in-built mic and speaker for clear, stable sound quality.\n",
    "Multiple Sports & Activity Modes â€“ From running and cycling to yoga and strength training, track your daily workouts with precision and view your progress in the companion app.\n",
    "Smart Notifications & Controls â€“ Get alerts for calls, SMS, WhatsApp, and social apps. Control music, camera, and more right from your wrist for effortless multitasking.'''})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01d81429",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain2 = prompt3 | llm3 | strparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "225e378d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Subject:** ðŸš€ Upgrade Your Wrist with Our **Smart Watch with HD Display** â€“ The Future of Wearable Tech!\\n\\n---\\n**Header:** *Crystal-clear visuals, hands-free calls, and precision fitness trackingâ€”all in one sleek device.*\\n\\n---\\n**Body:**\\n\\nHi [First Name],\\n\\nImagine a **smartwatch** that isnâ€™t just a fitness trackerâ€”itâ€™s your **all-in-one smart companion**! ðŸ’¡ With our **[Smart Watch with HD Display]**, you get **a stunning 1.5-inch circular HD screen** that delivers **rich color depth** and **smooth touch response**, plus **standalone phone features** with **nano-SIM support**â€”so you can stay connected *without* fumbling for your phone. **Never miss a beat again!**\\n\\n### **âœ¨ Why Youâ€™ll Love It:**\\n**1ï¸âƒ£ Premium Display for Stunning Visuals**\\n- **1.5-inch HD circular screen** â€“ Vibrant colors and crisp clarity, even in bright sunlight.\\n- **Always-on display** â€“ Quickly check the time without waking the screen.\\n- **Ideal for selfies, videos, and notifications** â€“ See every detail effortlessly.\\n\\n**2ï¸âƒ£ A *Real* Watch Phone Inside Your Wrist**\\n- **2 MP front-facing camera** â€“ Capture clear selfies and join high-quality video calls.\\n- **Built-in mic and speaker** â€“ Hands-free crystal-clear audio for calls, alerts, and music.\\n- **nano-SIM support** â€“ Stay connected hands-free with **standalone Bluetooth calling**.\\n\\n**3ï¸âƒ£ Built for Every Fitness Journey**\\n- **Precision tracking** for **running, cycling, yoga, weightlifting, and more**.\\n- **Compare progress & get insights** with the **companion app**.\\n- **Uninterrupted wellness monitoring** â€“ Track heart rate, steps, sleep, and recovery.\\n\\n**4ï¸âƒ£ Your Smart Assistant at a Glance**\\n- **On-wrist controls** for music, camera, calls, and notificationsâ€”*no phone needed*.\\n- **Effortless multitasking** â€“ Check messages, adjust workouts, and take selfies *all from your wrist*.\\n\\n**5ï¸âƒ£ Ultra-Reliable & Simple to Use**\\n- **Smooth, responsive touchscreen** â€“ Intuitive navigation for every feature.\\n- **Lightweight & comfortable** â€“ Perfect for all-day wear.\\n- **Designed for tech-savvy & casual users alike** â€“ No complexity, just convenience.\\n\\n### **ðŸŽ¯ Who Is It Perfect For?**\\nâœ” **Fitness Enthusiasts** â€“ Track every workout with ease.\\nâœ” **Busy Professionals** â€“ Respond to calls & messages without breaking stride.\\nâœ” **Casual Users** â€“ Stay connected without the hassle.\\nâœ” **Tech & Style Lovers** â€“ Sleek design meets powerful features.\\n\\n### **ðŸ’¥ Limited-Time Offer:**\\nGet **[Smart Watch with HD Display]** at **[Discount/Promotion, e.g., 20% off or \"Free wellness app for 1 year!\"]** for a limited time only! **[Shop Now]** or **[Learn More]**\\n\\nâ° **Donâ€™t waitâ€”upgrade your wrist today!**\\n\\n---\\n**Footer:**\\nðŸ“ **Need Help?** [Contact Support]\\nðŸ“² **Follow Us:** [Social Media Links]\\nðŸ“¦ **Free Shipping:** On orders over **[Amount]**\\nðŸ”’ **Secure & Hassle-Free Returns:** Weâ€™ve got you covered!\\n\\n---\\n**Call-to-Action Button:**\\n**\"Get My Smart Watch Now â€“ [Discount/Promotion]\"**\\n\\n---\\n**P.S.** Why look down when the answers are *right on your wrist*? **[Smart Watch with HD Display]** makes every day smarter, faster, and more connected. **[Start Your Smart Journey Today!]**\\n\\n---\\n**Variations for Different Audiences:**\\n- **For Athletes:** *\"Your next PR is just a tap awayâ€”with our precision tracking & nano-SIM convenience, youâ€™ll never miss a call or a workout detail.\"*\\n- **For Professionals:** *\"Elevate your productivity with hands-free calls, instant notifications, and sleek controlsâ€”all while looking sharp.\"*\\n- **For Casual Users:** *\"A smartwatch thatâ€™s easy to use, stylish, and keeps you connected without the clutter.\"*'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2.invoke(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0347a1",
   "metadata": {},
   "source": [
    "# **Parellel Chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaf58f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1 - Prompt Template\n",
    "\n",
    "prompt_main = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a Movie Summarizer.\"),\n",
    "    (\"user\", \"Generate a movie summary for the following movie in brief: {input}\")\n",
    "])\n",
    "\n",
    "# Task 2 - LLM \n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url = \"https://openrouter.ai/api/v1\", \n",
    "    model =\"mistralai/mistral-7b-instruct\", \n",
    "    temperature = 0.7, \n",
    "    api_key = os.getenv(\"OPENROUTER_API_KEY\"))\n",
    "\n",
    "# Task 3 - String Parser\n",
    "\n",
    "string_parser = StrOutputParser()\n",
    "\n",
    "# Task 4 - Dictionary Convertor\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def dictionary_maker(text: str) -> dict:\n",
    "    return {\"summary\": text}\n",
    "\n",
    "dictionary_maker_runnable = RunnableLambda(dictionary_maker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf4b36fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linked IN Post Generater\n",
    "\n",
    "prompt_linked_in = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a Linked IN Post Generater.\"),\n",
    "    (\"user\", \"Generate a Linked IN Post for the following movie summary: {summary}\")\n",
    "])\n",
    "\n",
    "chain_linked_in = prompt_linked_in | llm | string_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6609f6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instagram Post Generator\n",
    "\n",
    "prompt_insta = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a Instagram Post Generater.\"),\n",
    "    (\"user\", \"Generate a Instagram Post for the following movie summary: {summary}\")\n",
    "])\n",
    "\n",
    "chain_insta = prompt_insta | llm | string_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5b143e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "main_chain = prompt_main | llm | string_parser | dictionary_maker_runnable | RunnableParallel(branches= {\"Linked IN\": chain_linked_in, \"Instagram\": chain_insta})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b030dac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'branches': {'Linked IN': '**ðŸŽ¬ðŸ’« A Letter That Changed Lives: Why *Gifted* (2017) Resonates More Than Ever**\\n\\nSometimes, the most powerful stories arenâ€™t about grand heroes or high-stakes battlesâ€”theyâ€™re about the quiet moments of connection, healing, and self-discovery that shape us in ways we canâ€™t even see until we look back. *Gifted*, directed by **Marc Webb** and inspired by **Stephen Chboskyâ€™s *The Perks of Being a Wallflower***, is one of those stories.\\n\\nAt its heart, *Gifted* is about **Frank (Joseph Gordon-Levitt)**, a high school counselor who, after a series of missteps and personal demons, becomes the unexpected bridge to healing for **Charlie (Penn Badgley)**, a 15-year-old burdened by anxiety, loneliness, and the scars of a childhood trauma. Through their raw, honest exchangesâ€”letter by letterâ€”Frank helps Charlie break free from his silence, showing him that his pain, his quirks, and his struggles donâ€™t define him. Instead, theyâ€™re just pieces of a story waiting to be written with courage.\\n\\nAnd Charlie *does* find his voiceâ€”with **Samantha (Emmy Rossum)**, a free-spirited new girl with her own cracks, and with **Patrick (Rylan Clark-Neuen)**, the older brother who challenges him to see the world beyond his fears. Their relationships arenâ€™t perfect; theyâ€™re messy, imperfect, and *human*â€”just like the healing process itself.\\n\\nWhat makes *Gifted* truly special is how it **weaves two stories together**: Charlieâ€™s journey to reclaim his confidence and Frankâ€™s quiet redemption. The film reminds us that **no one heals alone**â€”and sometimes, the person who lifts us up isnâ€™t a mentor in title, but someone who understands our language, our silences, and our shared need for light.\\n\\nA bittersweet, deeply introspective tale about **the power of connection**, *Gifted* isnâ€™t just a coming-of-age storyâ€”itâ€™s a testament to how far we can go when someone believes in us. Have you read the book or seen the film? What moments stayed with you? ðŸ‘‡ #Gifted #StephenChbosky #ComingOfAge #Mentorship #Healing #EmotionalStorytelling #MarcWebb #JosephGordonLevitt #PennBadgley #EmmyRossum #BookToMovie #AnxietyAwareness\\n\\n*(Tag themed or relevant: #MentalHealthMatters #BooksThatChangeYou #ComingOfAgeMovies)*',\n",
       "  'Instagram': '**ðŸ“¸ INSTAGRAM POST FOR *GIFTED* (2017)**\\n\\n---\\n**âœ¨ Caption:**\\n*\"Sometimes the greatest gifts arenâ€™t wrapped in paperâ€¦ theyâ€™re the hands that hold yours when you feel lost. ðŸ’Œ In *GIFTED*, @josephglevitt becomes the bridge for @pennbadgleyâ€™s Charlieâ€”a quiet soul drowning in tides of silence, trauma, and self-doubt. Through letters, laughter, and raw honesty, Frank helps him find his voice, his light, and maybe even his way back to the world. ðŸŒŸ This isnâ€™t just a story about growing up; itâ€™s about healing, connection, and the beautiful mess of being human. A bittersweet masterpiece that will pull at your heartstrings and leave you breathless. ðŸŽ¥ðŸ’”ðŸ”¥*\\n\\n**#GiftedMovie #StephenChbosky #JosephGordonLevitt #PennBadgley #ComingOfAgeDrama #LettersHeal #FindingYourself #MentorshipMatters #BittersweetVibes #MarcWebb #MovieMagic #EmotionalJourney #NetflixMustWatch\"*\\n\\n---\\n**ðŸŽ¬ Visual Ideas:**\\n1. **Film Strip + Heart Symbol:**\\n   - *\"The best gifts come in lettersâ€¦ and the best stories come from the heart. ðŸ“šâ¤ï¸\"* (Overlay text on a close-up of a handwritten letter with a film strip in the background.)\\n\\n2. **Montage of Scenes:**\\n   - A quick collage of:\\n     - Frankâ€™s warm, expressive face writing in the letters.\\n     - Charlie in his first tender moment with Samantha.\\n     - The climax of the heartbreaking yet hopeful scene.\\n\\n3. **Thoughtful Close-Up:**\\n   - A single frame of Charlieâ€™s face, wide-eyed and vulnerable, with the caption:\\n   *\"What if someone saw you the way you really areâ€”and still loved you?\"*\\n\\n4. **Symbolic Icon:**\\n   - Use the ðŸ’Œ emoji or a simple \"PS\" tag with the caption:\\n   *\"Sometimes, all it takes is a â€˜PSâ€™ to change everythingâ€¦ #GiftedMovie\"*\\n\\n---\\n**ðŸ’¬ Hashtag Suggestions:**\\n*(Mix of mood and movie-related tags)*\\n- #ThePerksOfBeingAWallflower\\n- #SadButHopeful\\n- #LonelinessToLove\\n- #LettersThatSpeak\\n- #JosephGordonLevitt\\n- #EmmyRossum\\n- #MovieRecommendations\\n- #HealingThroughArt\\n- #NetflixDeepDive\\n- #QuietStrength\\n\\n---\\nWould you like a follow-up post (like a character breakdown or a throwback to the book)? Or a specific aesthetic (e.g., vintage, modern, emotional)? ðŸ˜Š'}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = main_chain.invoke({\"input\": \"Gifted\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa3aaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**ðŸŽ¬ðŸ’« A Letter That Changed Lives: Why *Gifted* (2017) Resonates More Than Ever**\n",
      "\n",
      "Sometimes, the most powerful stories arenâ€™t about grand heroes or high-stakes battlesâ€”theyâ€™re about the quiet moments of connection, healing, and self-discovery that shape us in ways we canâ€™t even see until we look back. *Gifted*, directed by **Marc Webb** and inspired by **Stephen Chboskyâ€™s *The Perks of Being a Wallflower***, is one of those stories.\n",
      "\n",
      "At its heart, *Gifted* is about **Frank (Joseph Gordon-Levitt)**, a high school counselor who, after a series of missteps and personal demons, becomes the unexpected bridge to healing for **Charlie (Penn Badgley)**, a 15-year-old burdened by anxiety, loneliness, and the scars of a childhood trauma. Through their raw, honest exchangesâ€”letter by letterâ€”Frank helps Charlie break free from his silence, showing him that his pain, his quirks, and his struggles donâ€™t define him. Instead, theyâ€™re just pieces of a story waiting to be written with courage.\n",
      "\n",
      "And Charlie *does* find his voiceâ€”with **Samantha (Emmy Rossum)**, a free-spirited new girl with her own cracks, and with **Patrick (Rylan Clark-Neuen)**, the older brother who challenges him to see the world beyond his fears. Their relationships arenâ€™t perfect; theyâ€™re messy, imperfect, and *human*â€”just like the healing process itself.\n",
      "\n",
      "What makes *Gifted* truly special is how it **weaves two stories together**: Charlieâ€™s journey to reclaim his confidence and Frankâ€™s quiet redemption. The film reminds us that **no one heals alone**â€”and sometimes, the person who lifts us up isnâ€™t a mentor in title, but someone who understands our language, our silences, and our shared need for light.\n",
      "\n",
      "A bittersweet, deeply introspective tale about **the power of connection**, *Gifted* isnâ€™t just a coming-of-age storyâ€”itâ€™s a testament to how far we can go when someone believes in us. Have you read the book or seen the film? What moments stayed with you? ðŸ‘‡ #Gifted #StephenChbosky #ComingOfAge #Mentorship #Healing #EmotionalStorytelling #MarcWebb #JosephGordonLevitt #PennBadgley #EmmyRossum #BookToMovie #AnxietyAwareness\n",
      "\n",
      "*(Tag themed or relevant: #MentalHealthMatters #BooksThatChangeYou #ComingOfAgeMovies)*\n"
     ]
    }
   ],
   "source": [
    "print(response[\"branches\"][\"Linked IN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "359e5b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**ðŸ“¸ INSTAGRAM POST FOR *GIFTED* (2017)**\n",
      "\n",
      "---\n",
      "**âœ¨ Caption:**\n",
      "*\"Sometimes the greatest gifts arenâ€™t wrapped in paperâ€¦ theyâ€™re the hands that hold yours when you feel lost. ðŸ’Œ In *GIFTED*, @josephglevitt becomes the bridge for @pennbadgleyâ€™s Charlieâ€”a quiet soul drowning in tides of silence, trauma, and self-doubt. Through letters, laughter, and raw honesty, Frank helps him find his voice, his light, and maybe even his way back to the world. ðŸŒŸ This isnâ€™t just a story about growing up; itâ€™s about healing, connection, and the beautiful mess of being human. A bittersweet masterpiece that will pull at your heartstrings and leave you breathless. ðŸŽ¥ðŸ’”ðŸ”¥*\n",
      "\n",
      "**#GiftedMovie #StephenChbosky #JosephGordonLevitt #PennBadgley #ComingOfAgeDrama #LettersHeal #FindingYourself #MentorshipMatters #BittersweetVibes #MarcWebb #MovieMagic #EmotionalJourney #NetflixMustWatch\"*\n",
      "\n",
      "---\n",
      "**ðŸŽ¬ Visual Ideas:**\n",
      "1. **Film Strip + Heart Symbol:**\n",
      "   - *\"The best gifts come in lettersâ€¦ and the best stories come from the heart. ðŸ“šâ¤ï¸\"* (Overlay text on a close-up of a handwritten letter with a film strip in the background.)\n",
      "\n",
      "2. **Montage of Scenes:**\n",
      "   - A quick collage of:\n",
      "     - Frankâ€™s warm, expressive face writing in the letters.\n",
      "     - Charlie in his first tender moment with Samantha.\n",
      "     - The climax of the heartbreaking yet hopeful scene.\n",
      "\n",
      "3. **Thoughtful Close-Up:**\n",
      "   - A single frame of Charlieâ€™s face, wide-eyed and vulnerable, with the caption:\n",
      "   *\"What if someone saw you the way you really areâ€”and still loved you?\"*\n",
      "\n",
      "4. **Symbolic Icon:**\n",
      "   - Use the ðŸ’Œ emoji or a simple \"PS\" tag with the caption:\n",
      "   *\"Sometimes, all it takes is a â€˜PSâ€™ to change everythingâ€¦ #GiftedMovie\"*\n",
      "\n",
      "---\n",
      "**ðŸ’¬ Hashtag Suggestions:**\n",
      "*(Mix of mood and movie-related tags)*\n",
      "- #ThePerksOfBeingAWallflower\n",
      "- #SadButHopeful\n",
      "- #LonelinessToLove\n",
      "- #LettersThatSpeak\n",
      "- #JosephGordonLevitt\n",
      "- #EmmyRossum\n",
      "- #MovieRecommendations\n",
      "- #HealingThroughArt\n",
      "- #NetflixDeepDive\n",
      "- #QuietStrength\n",
      "\n",
      "---\n",
      "Would you like a follow-up post (like a character breakdown or a throwback to the book)? Or a specific aesthetic (e.g., vintage, modern, emotional)? ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "print(response[\"branches\"][\"Instagram\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94642c2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid variable name 'branches[summary]' in f-string template. Variable names cannot contain attribute access (.) or indexing ([]).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 96\u001b[39m\n\u001b[32m     84\u001b[39m risk_chain = (\n\u001b[32m     85\u001b[39m     risk_prompt\n\u001b[32m     86\u001b[39m     | llm.with_structured_output(Risks)\n\u001b[32m     87\u001b[39m     | RunnableLambda(risk_parser)\n\u001b[32m     88\u001b[39m )\n\u001b[32m     90\u001b[39m parallel_chain = RunnableParallel(\n\u001b[32m     91\u001b[39m     product=product_chain,\n\u001b[32m     92\u001b[39m     audience=audience_chain,\n\u001b[32m     93\u001b[39m     risks=risk_chain\n\u001b[32m     94\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m final_prompt = \u001b[43mChatPromptTemplate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_template\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;250;43m    \u001b[39;49m\u001b[33;43;03m\"\"\"\u001b[39;49;00m\n\u001b[32m     98\u001b[39m \u001b[33;43;03mCreate an investor pitch summary using the information below.\u001b[39;49;00m\n\u001b[32m     99\u001b[39m \n\u001b[32m    100\u001b[39m \u001b[33;43;03mProduct Name:\u001b[39;49;00m\n\u001b[32m    101\u001b[39m \u001b[33;43;03m{branches[product_name]}\u001b[39;49;00m\n\u001b[32m    102\u001b[39m \n\u001b[32m    103\u001b[39m \u001b[33;43;03mProduct Summary:\u001b[39;49;00m\n\u001b[32m    104\u001b[39m \u001b[33;43;03m{branches[summary]}\u001b[39;49;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;43;03mTarget Audience:\u001b[39;49;00m\n\u001b[32m    107\u001b[39m \u001b[33;43;03m{branches[user_type]}\u001b[39;49;00m\n\u001b[32m    108\u001b[39m \n\u001b[32m    109\u001b[39m \u001b[33;43;03mUser Problem:\u001b[39;49;00m\n\u001b[32m    110\u001b[39m \u001b[33;43;03m{branches[problem]}\u001b[39;49;00m\n\u001b[32m    111\u001b[39m \n\u001b[32m    112\u001b[39m \u001b[33;43;03mRisks:\u001b[39;49;00m\n\u001b[32m    113\u001b[39m \u001b[33;43;03m{branches[risks]}\u001b[39;49;00m\n\u001b[32m    114\u001b[39m \n\u001b[32m    115\u001b[39m \u001b[33;43;03mTechnical Challenge:\u001b[39;49;00m\n\u001b[32m    116\u001b[39m \u001b[33;43;03m{branches[technical_challenge]}\u001b[39;49;00m\n\u001b[32m    117\u001b[39m \u001b[33;43;03m\"\"\"\u001b[39;49;00m\n\u001b[32m    118\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m final_chain = (\n\u001b[32m    121\u001b[39m     parallel_chain\n\u001b[32m    122\u001b[39m     | final_prompt\n\u001b[32m    123\u001b[39m     | llm\n\u001b[32m    124\u001b[39m     | str_parser\n\u001b[32m    125\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Langchain_Proj\\.venv\\Lib\\site-packages\\langchain_core\\prompts\\chat.py:1114\u001b[39m, in \u001b[36mChatPromptTemplate.from_template\u001b[39m\u001b[34m(cls, template, **kwargs)\u001b[39m\n\u001b[32m   1100\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_template\u001b[39m(\u001b[38;5;28mcls\u001b[39m, template: \u001b[38;5;28mstr\u001b[39m, **kwargs: Any) -> ChatPromptTemplate:\n\u001b[32m   1102\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create a chat prompt template from a template string.\u001b[39;00m\n\u001b[32m   1103\u001b[39m \n\u001b[32m   1104\u001b[39m \u001b[33;03m    Creates a chat template consisting of a single message assumed to be from the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1112\u001b[39m \u001b[33;03m        A new instance of this class.\u001b[39;00m\n\u001b[32m   1113\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1114\u001b[39m     prompt_template = \u001b[43mPromptTemplate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_template\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1115\u001b[39m     message = HumanMessagePromptTemplate(prompt=prompt_template)\n\u001b[32m   1116\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.from_messages([message])\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Langchain_Proj\\.venv\\Lib\\site-packages\\langchain_core\\prompts\\prompt.py:298\u001b[39m, in \u001b[36mPromptTemplate.from_template\u001b[39m\u001b[34m(cls, template, template_format, partial_variables, **kwargs)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_template\u001b[39m(\n\u001b[32m    258\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    263\u001b[39m     **kwargs: Any,\n\u001b[32m    264\u001b[39m ) -> PromptTemplate:\n\u001b[32m    265\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load a prompt template from a template.\u001b[39;00m\n\u001b[32m    266\u001b[39m \n\u001b[32m    267\u001b[39m \u001b[33;03m    !!! warning \"Security\"\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    296\u001b[39m \u001b[33;03m        The prompt template loaded from the template.\u001b[39;00m\n\u001b[32m    297\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m     input_variables = \u001b[43mget_template_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    299\u001b[39m     partial_variables_ = partial_variables \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m    301\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m partial_variables_:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Langchain_Proj\\.venv\\Lib\\site-packages\\langchain_core\\prompts\\string.py:294\u001b[39m, in \u001b[36mget_template_variables\u001b[39m\u001b[34m(template, template_format)\u001b[39m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m var \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m var \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m var:\n\u001b[32m    289\u001b[39m     msg = (\n\u001b[32m    290\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid variable name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m in f-string template. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    291\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVariable names cannot contain attribute \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    292\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33maccess (.) or indexing ([]).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    293\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    296\u001b[39m \u001b[38;5;66;03m# Block variable names that are all digits (e.g., \"0\", \"100\")\u001b[39;00m\n\u001b[32m    297\u001b[39m \u001b[38;5;66;03m# These are interpreted as positional arguments, not keyword arguments\u001b[39;00m\n\u001b[32m    298\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m var.isdigit():\n",
      "\u001b[31mValueError\u001b[39m: Invalid variable name 'branches[summary]' in f-string template. Variable names cannot contain attribute access (.) or indexing ([])."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "if os.getenv(\"OPENROUTER_API_KEY\") is None:\n",
    "    raise RuntimeError(\"OpenRouter API Key Not Found\")\n",
    "\n",
    "API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=API_KEY,\n",
    "    model=\"mistralai/mistral-7b-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "str_parser = StrOutputParser()\n",
    "\n",
    "class ProductSummary(BaseModel):\n",
    "    product_name: str\n",
    "    summary: str\n",
    "\n",
    "class TargetAudience(BaseModel):\n",
    "    user_type: str\n",
    "    problem: str\n",
    "\n",
    "class Risks(BaseModel):\n",
    "    risks: List[str]\n",
    "    technical_challenge: str\n",
    "\n",
    "product_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Based on the startup idea below, extract product details.\n",
    "\n",
    "Startup Idea:\n",
    "{startup_idea}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "def product_parser(data) -> dict:\n",
    "    return data.model_dump()\n",
    "\n",
    "product_chain = (\n",
    "    product_prompt\n",
    "    | llm.with_structured_output(ProductSummary)\n",
    "    | RunnableLambda(product_parser)\n",
    ")\n",
    "\n",
    "audience_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Based on the startup idea below, identify the target audience.\n",
    "\n",
    "Startup Idea:\n",
    "{startup_idea}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "def audience_parser(data) -> dict:\n",
    "    return data.model_dump()\n",
    "\n",
    "audience_chain = (\n",
    "    audience_prompt\n",
    "    | llm.with_structured_output(TargetAudience)\n",
    "    | RunnableLambda(audience_parser)\n",
    ")\n",
    "\n",
    "risk_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Based on the startup idea below, identify risks.\n",
    "\n",
    "Startup Idea:\n",
    "{startup_idea}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "def risk_parser(data) -> dict:\n",
    "    return data.model_dump()\n",
    "\n",
    "risk_chain = (\n",
    "    risk_prompt\n",
    "    | llm.with_structured_output(Risks)\n",
    "    | RunnableLambda(risk_parser)\n",
    ")\n",
    "\n",
    "parallel_chain = RunnableParallel(\n",
    "    product=product_chain,\n",
    "    audience=audience_chain,\n",
    "    risks=risk_chain\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Create an investor pitch summary using the information below.\n",
    "\n",
    "Product Name:\n",
    "{branches[product_name]}\n",
    "\n",
    "Product Summary:\n",
    "{branches[summary]}\n",
    "\n",
    "Target Audience:\n",
    "{branches[user_type]}\n",
    "\n",
    "User Problem:\n",
    "{branches[problem]}\n",
    "\n",
    "Risks:\n",
    "{branches[risks]}\n",
    "\n",
    "Technical Challenge:\n",
    "{branches[technical_challenge]}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "final_chain = (\n",
    "    parallel_chain\n",
    "    | final_prompt\n",
    "    | llm\n",
    "    | str_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4fe60758",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Input to ChatPromptTemplate is missing variables {'product_name', 'problem', 'user_type', 'technical_challenge', 'summary'}.  Expected: ['problem', 'product_name', 'risks', 'summary', 'technical_challenge', 'user_type'] Received: ['product', 'audience', 'risks']\\nNote: if you intended {product_name} to be part of the string and not a variable, please escape it with double curly braces like: '{{product_name}}'.\\nFor troubleshooting, visit: https://docs.langchain.com/oss/python/langchain/errors/INVALID_PROMPT_INPUT \"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m startup_idea = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[33mA SaaS platform that helps small retail businesses predict inventory demand\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33musing AI-powered analytics. The platform integrates with existing POS systems,\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[33mprovides real-time sales insights, and reduces stock wastage.\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m result = \u001b[43mfinal_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstartup_idea\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstartup_idea\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Langchain_Proj\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3153\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3151\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3152\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3153\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3154\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3155\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Langchain_Proj\\.venv\\Lib\\site-packages\\langchain_core\\prompts\\base.py:223\u001b[39m, in \u001b[36mBasePromptTemplate.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tags:\n\u001b[32m    222\u001b[39m     config[\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[38;5;28mself\u001b[39m.tags\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_format_prompt_with_error_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserialized\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_serialized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Langchain_Proj\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2060\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   2056\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   2057\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   2058\u001b[39m         output = cast(\n\u001b[32m   2059\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m2060\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2061\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   2062\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2063\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2064\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2065\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2066\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2067\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   2068\u001b[39m         )\n\u001b[32m   2069\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2070\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Langchain_Proj\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:452\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    451\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m452\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Langchain_Proj\\.venv\\Lib\\site-packages\\langchain_core\\prompts\\base.py:196\u001b[39m, in \u001b[36mBasePromptTemplate._format_prompt_with_error_handling\u001b[39m\u001b[34m(self, inner_input)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_format_prompt_with_error_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, inner_input: \u001b[38;5;28mdict\u001b[39m) -> PromptValue:\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m     inner_input_ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.format_prompt(**inner_input_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Langchain_Proj\\.venv\\Lib\\site-packages\\langchain_core\\prompts\\base.py:190\u001b[39m, in \u001b[36mBasePromptTemplate._validate_input\u001b[39m\u001b[34m(self, inner_input)\u001b[39m\n\u001b[32m    184\u001b[39m     example_key = missing.pop()\n\u001b[32m    185\u001b[39m     msg += (\n\u001b[32m    186\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mNote: if you intended \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[33m to be part of the string\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    187\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m and not a variable, please escape it with double curly braces like: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    188\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    189\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m    191\u001b[39m         create_message(message=msg, error_code=ErrorCode.INVALID_PROMPT_INPUT)\n\u001b[32m    192\u001b[39m     )\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m inner_input_\n",
      "\u001b[31mKeyError\u001b[39m: \"Input to ChatPromptTemplate is missing variables {'product_name', 'problem', 'user_type', 'technical_challenge', 'summary'}.  Expected: ['problem', 'product_name', 'risks', 'summary', 'technical_challenge', 'user_type'] Received: ['product', 'audience', 'risks']\\nNote: if you intended {product_name} to be part of the string and not a variable, please escape it with double curly braces like: '{{product_name}}'.\\nFor troubleshooting, visit: https://docs.langchain.com/oss/python/langchain/errors/INVALID_PROMPT_INPUT \""
     ]
    }
   ],
   "source": [
    "startup_idea = \"\"\"\n",
    "A SaaS platform that helps small retail businesses predict inventory demand\n",
    "using AI-powered analytics. The platform integrates with existing POS systems,\n",
    "provides real-time sales insights, and reduces stock wastage.\n",
    "\"\"\"\n",
    "\n",
    "result = final_chain.invoke(\n",
    "    {\"startup_idea\": startup_idea}\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
